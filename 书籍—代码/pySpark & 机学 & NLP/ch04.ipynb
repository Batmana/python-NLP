{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "international-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch04: 线性回归\n",
    "# 步骤1: 创建SparkSession对象\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lin_reg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handy-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤2: 读取数据集\n",
    "df = spark.read.csv(\"Linear_regression_dataset.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "functional-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232 6\n"
     ]
    }
   ],
   "source": [
    "# 步骤3: 探究式数据分析\n",
    "print(df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surgical-doubt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continent-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|var_1            |var_2            |var_3             |var_4               |var_5               |output             |\n",
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|count  |1232             |1232             |1232              |1232                |1232                |1232               |\n",
      "|mean   |715.0819805194806|715.0819805194806|80.90422077922078 |0.3263311688311693  |0.25927272727272715 |0.39734172077922014|\n",
      "|stddev |91.5342940441652 |93.07993263118064|11.458139049993724|0.015012772334166148|0.012907228928000298|0.03326689862173776|\n",
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portuguese-respondent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(var_1=734, var_2=688, var_3=81, var_4=0.328, var_5=0.259, output=0.418),\n",
       " Row(var_1=700, var_2=600, var_3=94, var_4=0.32, var_5=0.247, output=0.389),\n",
       " Row(var_1=712, var_2=705, var_3=93, var_4=0.311, var_5=0.247, output=0.417)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "earlier-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|corr(var_1, output)|\n",
      "+-------------------+\n",
      "| 0.9187399607627283|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "df.select(corr('var_1', 'output')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automotive-accountability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'output']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 步骤4: 特征工程化\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "precious-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['var_1', 'var_2', 'var_3', 'var_4', 'var_5'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confidential-digest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df = vec_assembler.transform(df)\n",
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vertical-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|features                      |\n",
      "+------------------------------+\n",
      "|[734.0,688.0,81.0,0.328,0.259]|\n",
      "|[700.0,600.0,94.0,0.32,0.247] |\n",
      "|[712.0,705.0,93.0,0.311,0.247]|\n",
      "|[734.0,806.0,69.0,0.315,0.26] |\n",
      "|[613.0,759.0,61.0,0.302,0.24] |\n",
      "+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.select('features').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "resident-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = features_df.select('features', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "difficult-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+\n",
      "|features                      |output|\n",
      "+------------------------------+------+\n",
      "|[734.0,688.0,81.0,0.328,0.259]|0.418 |\n",
      "|[700.0,600.0,94.0,0.32,0.247] |0.389 |\n",
      "|[712.0,705.0,93.0,0.311,0.247]|0.417 |\n",
      "|[734.0,806.0,69.0,0.315,0.26] |0.415 |\n",
      "|[613.0,759.0,61.0,0.302,0.24] |0.378 |\n",
      "+------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "religious-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232 2\n"
     ]
    }
   ],
   "source": [
    "print(model_df.count(), len(model_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recovered-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 2)\n"
     ]
    }
   ],
   "source": [
    "# 步骤5: 划分数据集\n",
    "train_df, test_df = model_df.randomSplit([0.7, 0.3])\n",
    "print((train_df.count(), len(train_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "touched-calculation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 2)\n"
     ]
    }
   ],
   "source": [
    "print((test_df.count(), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "floating-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00033045422117331137,5.0535719966951864e-05,0.00020349082704125253,-0.6236352275559593,0.53749365191754]\n"
     ]
    }
   ],
   "source": [
    "# 步骤6: 构建和训练线性回归模型\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lin_Reg = LinearRegression(labelCol='output')\n",
    "lr_model = lin_Reg.fit(train_df)\n",
    "print(lr_model.coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "least-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17248193161067485\n"
     ]
    }
   ],
   "source": [
    "print(lr_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "flush-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions=lr_model.evaluate(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "finished-connecticut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8689707188189623\n"
     ]
    }
   ],
   "source": [
    "print(train_predictions.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤7: 在测试数据集上评估线性回归模型\n",
    "test_predictions=lr_model.evaluate(test_df)\n",
    "print(test_predictions.r2)\n",
    "pruint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
